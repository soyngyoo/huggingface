{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c181c1-37af-418a-8b6c-9020854f5e02",
   "metadata": {},
   "source": [
    "# **Understanding pipelines, models and schedulers**\n",
    "\n",
    "- ì‘ì„±ì¼ : 24.07.30  \n",
    "- ì‘ì„±ì : ìœ ì†Œì˜  \n",
    "- ì¶œì²˜ : https://huggingface.co/docs/diffusers/using-diffusers/write_own_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfe05ca-73c6-4500-be1c-2166014599ae",
   "metadata": {},
   "source": [
    "DiffusersëŠ” ì‚¬ìš©ì ì¹œí™”ì ì´ê³  ìœ ì—°í•œ ë„êµ¬ë¡œ, ë‹¹ì‹ ì˜ ì‚¬ìš© ì‚¬ë¡€ì— ë§ëŠ” í™•ì‚° ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ì´ ë„êµ¬ì˜ í•µì‹¬ì€ <u>ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬</u>ì…ë‹ˆë‹¤. DiffusionPipelineì´ í¸ì˜ë¥¼ ìœ„í•´ ì´ êµ¬ì„± ìš”ì†Œë“¤ì„ í•¨ê»˜ ë¬¶ì–´ì£¼ì§€ë§Œ, íŒŒì´í”„ë¼ì¸ì„ í•´ì²´í•˜ì—¬ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•´ ìƒˆë¡œìš´ í™•ì‚° ì‹œìŠ¤í…œì„ ë§Œë“¤ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ë¡ ì„ ìœ„í•œ í™•ì‚° ì‹œìŠ¤í…œì„ ì¡°ë¦½í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤. ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ë¶€í„° ì‹œì‘í•´ Stable Diffusion íŒŒì´í”„ë¼ì¸ê¹Œì§€ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê¸°ë³¸ íŒŒì´í”„ë¼ì¸ í•´ì²´í•˜ê¸°\n",
    "íŒŒì´í”„ë¼ì¸ì€ ëª¨ë¸ì„ ì¶”ë¡ ì— ì‚¬ìš©í•˜ëŠ” ë¹ ë¥´ê³  ì‰¬ìš´ ë°©ë²•ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ë‹¨ 4ì¤„ì˜ ì½”ë“œë§Œ í•„ìš”í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11df14e1-62d4-4649-932e-f544c6027a4b",
   "metadata": {},
   "source": [
    "## Deconstruct a basic pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d2e20-1f75-44f5-83e5-b11af66dfc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMPipeline\n",
    "\n",
    "ddpm = DDPMPipeline.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")\n",
    "image = ddpm(num_inference_steps=250).images[0]\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7f39c8-f601-4d62-bd87-12b003fe8c0f",
   "metadata": {},
   "source": [
    "ì´ ê³¼ì •ì€ ë§¤ìš° ê°„ë‹¨í•´ ë³´ì´ì§€ë§Œ, íŒŒì´í”„ë¼ì¸ì´ ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€ ìì„¸íˆ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ ì˜ˆì‹œì—ì„œ íŒŒì´í”„ë¼ì¸ì€ UNet2DModel ëª¨ë¸ê³¼ DDPMSchedulerë¥¼ í¬í•¨í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ì›í•˜ëŠ” ì¶œë ¥ í¬ê¸°ì˜ ëœë¤ ë…¸ì´ì¦ˆë¥¼ ì—¬ëŸ¬ ë²ˆ ëª¨ë¸ì— í†µê³¼ì‹œì¼œ ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•©ë‹ˆë‹¤.  \n",
    "ê° timestepì—ì„œ ëª¨ë¸ì€ 'ë…¸ì´ì¦ˆ ì”ì°¨'ë¥¼ ì˜ˆì¸¡í•˜ê³ , ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” ì´ë¥¼ ì‚¬ìš©í•´ ëœ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. íŒŒì´í”„ë¼ì¸ì€ ì§€ì •ëœ ì¶”ë¡  ë‹¨ê³„ ìˆ˜ì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì´ ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ë³„ë„ë¡œ ì‚¬ìš©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ì„ ì¬í˜„í•˜ê¸° ìœ„í•´, ìì²´ì ì¸ ë””ë…¸ì´ì§• í”„ë¡œì„¸ìŠ¤ë¥¼ ì‘ì„±í•´ ë³´ê² ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "**1. Load the model and scheduler:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481d6b4-5103-47d2-9b37-0d07f94b5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDPMScheduler, UNet2DModel\n",
    "\n",
    "scheduler = DDPMScheduler.from_pretrained(\"google/ddpm-cat-256\")\n",
    "model = UNet2DModel.from_pretrained(\"google/ddpm-cat-256\", use_safetensors=True).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6605d-874a-423b-b19c-94e72cb2e5a4",
   "metadata": {},
   "source": [
    "**2. Set the number of timesteps to run the denoising process for:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd67bd-59cb-4490-a1f4-7c21cd5cdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler.set_timesteps(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12481c17-5068-40cc-88b0-812b45208898",
   "metadata": {},
   "source": [
    "**3. ìŠ¤ì¼€ì¤„ëŸ¬ timestepsë¥¼ ì„¤ì •í•˜ë©´ ê· ì¼í•˜ê²Œ ë¶„í¬ëœ ìš”ì†Œë¥¼ ê°€ì§„ í…ì„œê°€ ìƒì„±ë©ë‹ˆë‹¤. ì´ ì˜ˆì‹œì—ì„œëŠ” 50ê°œì…ë‹ˆë‹¤. ê° ìš”ì†ŒëŠ” ëª¨ë¸ì´ ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ëŠ” timestepì— í•´ë‹¹í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë””ë…¸ì´ì§• ë£¨í”„ë¥¼ ë§Œë“¤ ë•Œ, ì´ í…ì„œë¥¼ ë°˜ë³µí•˜ë©° ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆë¥¼ ì œê±°í•˜ê²Œ ë©ë‹ˆë‹¤:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291cabc-7f5c-435c-9728-604db3302e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scheduler.timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7eb6d2-3368-45cf-8435-ba3490fc1fa5",
   "metadata": {},
   "source": [
    "**4. ì›í•˜ëŠ” ì¶œë ¥ê³¼ ê°™ì€ í˜•íƒœì˜ ëœë¤ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6f31c-2227-42a9-a68b-0577d282c3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sample_size = model.config.sample_size\n",
    "noise = torch.randn((1, 3, sample_size, sample_size), device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259826f-b42e-4480-929d-298eef4b5aff",
   "metadata": {},
   "source": [
    "**5. ì´ì œ timestepsë¥¼ ë°˜ë³µí•˜ëŠ” ë£¨í”„ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.**  ê° timestepì—ì„œ ëª¨ë¸ì€ UNet2DModel.forward() íŒ¨ìŠ¤ë¥¼ ìˆ˜í–‰í•˜ê³  ë…¸ì´ì¦ˆ ì”ì°¨ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ìŠ¤ì¼€ì¤„ëŸ¬ì˜ step() ë©”ì†Œë“œëŠ” ë…¸ì´ì¦ˆ ì”ì°¨, timestep, ê·¸ë¦¬ê³  ì…ë ¥ì„ ë°›ì•„ ì´ì „ timestepì˜ ì´ë¯¸ì§€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ ì¶œë ¥ì€ ë””ë…¸ì´ì§• ë£¨í”„ì—ì„œ ëª¨ë¸ì˜ ë‹¤ìŒ ì…ë ¥ì´ ë˜ë©°, `timesteps` ë°°ì—´ì˜ ëì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì´ ê³¼ì •ì´ ë°˜ë³µë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d90af1-5dad-4119-ad84-3d1980bec47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = noise\n",
    "\n",
    "for t in scheduler.timesteps:\n",
    "    with torch.no_grad():\n",
    "        noisy_residual = model(input, t).sample\n",
    "    previous_noisy_sample = scheduler.step(noisy_residual, t, input).prev_sample\n",
    "    input = previous_noisy_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ae0f5-eb60-47a1-b073-a9cae7e1c6dc",
   "metadata": {},
   "source": [
    "**6. The last step is to convert the denoised output into an image:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994fda24-5010-46ff-9d44-255aedc8c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image = (input / 2 + 0.5).clamp(0, 1).squeeze()\n",
    "image = (image.permute(1, 2, 0) * 255).round().to(torch.uint8).cpu().numpy()\n",
    "image = Image.fromarray(image)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf5a23-c517-4c66-ab39-0031c80f9faf",
   "metadata": {},
   "source": [
    "## Deconstruct the Stable Diffusion pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa16006-7c82-47d0-a1e5-36c0c7eb354e",
   "metadata": {},
   "source": [
    "Stable Diffusionì€ í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ 'ì ì¬ í™•ì‚°(Latent Diffusion)' ëª¨ë¸ì…ë‹ˆë‹¤. 'ì ì¬ í™•ì‚°' ëª¨ë¸ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
    "\n",
    "ì‹¤ì œ í”½ì…€ ê³µê°„ ëŒ€ì‹  ì´ë¯¸ì§€ì˜ ì €ì°¨ì› í‘œí˜„ì„ ë‹¤ë£¹ë‹ˆë‹¤. ì´ë¡œ ì¸í•´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì´ ë†’ì•„ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "Stable Diffusion ëª¨ë¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œ:\n",
    "\n",
    "- ì¸ì½”ë”: ì´ë¯¸ì§€ë¥¼ ë” ì‘ì€ í‘œí˜„ìœ¼ë¡œ ì••ì¶•í•©ë‹ˆë‹¤.\n",
    "- ë””ì½”ë”: ì••ì¶•ëœ í‘œí˜„ì„ ë‹¤ì‹œ ì´ë¯¸ì§€ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- í† í¬ë‚˜ì´ì €ì™€ ì¸ì½”ë”: í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤ (í…ìŠ¤íŠ¸-ì´ë¯¸ì§€ ëª¨ë¸ì— í•„ìš”).\n",
    "- UNet ëª¨ë¸: ì´ì „ ì˜ˆì œì—ì„œ ë³¸ ê²ƒê³¼ ê°™ì€ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "- ìŠ¤ì¼€ì¤„ëŸ¬: ë…¸ì´ì¦ˆ ì œê±° ê³¼ì •ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” UNet ëª¨ë¸ë§Œ í¬í•¨í•˜ëŠ” DDPM íŒŒì´í”„ë¼ì¸ë³´ë‹¤ í›¨ì”¬ ë³µì¡í•©ë‹ˆë‹¤. Stable Diffusion ëª¨ë¸ì€ ì„¸ ê°œì˜ ë³„ë„ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ê°€ì§€ê³  ìˆì–´ êµ¬ì¡°ê°€ ë” ë³µì¡í•©ë‹ˆë‹¤. Stable Diffusion íŒŒì´í”„ë¼ì¸ì— í•„ìš”í•œ êµ¬ì„± ìš”ì†Œë“¤ì„ ì•Œì•˜ìœ¼ë‹ˆ, from_pretrained() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•´ ì´ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ë¡œë“œí•˜ê² ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "ì´ë“¤ì€ ì‚¬ì „ í›ˆë ¨ëœ runwayml/stable-diffusion-v1-5 ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìœ¼ë©°, ê° êµ¬ì„± ìš”ì†ŒëŠ” ë³„ë„ì˜ í•˜ìœ„ í´ë”ì— ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872ad8b-490d-4a8a-81a6-0c2b5cd0dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import CLIPTextModel, CLIPTokenizer\n",
    "from diffusers import AutoencoderKL, UNet2DConditionModel, PNDMScheduler\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\", use_safetensors=True)\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"tokenizer\")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"text_encoder\", use_safetensors=True\n",
    ")\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\", subfolder=\"unet\", use_safetensors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7864137-3158-4936-9d98-04dde41dfc9d",
   "metadata": {},
   "source": [
    "ê¸°ë³¸ PNDMScheduler ëŒ€ì‹  UniPCMultistepSchedulerë¡œ êµì²´í•˜ì—¬ ë‹¤ë¥¸ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì–¼ë§ˆë‚˜ ì‰½ê²Œ ì—°ê²°í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•´ ë³´ê² ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cb43e6-aa6f-47b7-ab7d-e774895594b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import UniPCMultistepScheduler\n",
    "\n",
    "scheduler = UniPCMultistepScheduler.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"scheduler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad1bcc7-754a-463c-acde-7c3f51fc59cd",
   "metadata": {},
   "source": [
    "ì¶”ë¡  ì†ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´, ìŠ¤ì¼€ì¤„ëŸ¬ì™€ ë‹¬ë¦¬ í›ˆë ¨ ê°€ëŠ¥í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§„ ëª¨ë¸ë“¤ì„ GPUë¡œ ì´ë™ì‹œí‚µë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7193a31-59d9-437e-becf-d2a126a95469",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_device = \"cuda\"\n",
    "vae.to(torch_device)\n",
    "text_encoder.to(torch_device)\n",
    "unet.to(torch_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceea16e-de73-479c-aa34-29dcfb95174d",
   "metadata": {},
   "source": [
    "**í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±**  \n",
    "ë‹¤ìŒ ë‹¨ê³„ëŠ” í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ì—¬ ì„ë² ë”©ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ í…ìŠ¤íŠ¸ëŠ” UNet ëª¨ë¸ì„ ì¡°ê±´í™”í•˜ê³  í™•ì‚° ê³¼ì •ì„ ì…ë ¥ í”„ë¡¬í”„íŠ¸ì™€ ìœ ì‚¬í•œ ë°©í–¥ìœ¼ë¡œ ìœ ë„í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "ğŸ’¡ `guidance_scale` ë§¤ê°œë³€ìˆ˜ëŠ” ì´ë¯¸ì§€ ìƒì„± ì‹œ í”„ë¡¬í”„íŠ¸ì— ì–¼ë§ˆë‚˜ ê°€ì¤‘ì¹˜ë¥¼ ì¤„ì§€ ê²°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë¥¸ ê²ƒì„ ìƒì„±í•˜ê³  ì‹¶ë‹¤ë©´ ì›í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ììœ ë¡­ê²Œ ì„ íƒí•˜ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc527a-21b7-442e-8538-ffae8dab4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"a photograph of an astronaut riding a horse\"]\n",
    "height = 512  # default height of Stable Diffusion\n",
    "width = 512  # default width of Stable Diffusion\n",
    "num_inference_steps = 100  # Number of denoising steps\n",
    "guidance_scale = 7.5  # Scale for classifier-free guidance\n",
    "generator = torch.manual_seed(0)  # Seed generator to create the initial latent noise\n",
    "batch_size = len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393bf5f-a7e8-48fb-b484-1baa63d719a2",
   "metadata": {},
   "source": [
    "Tokenize the text and generate the embeddings from the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ca331-28e2-4a35-b53e-9f8c60ef509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = tokenizer(\n",
    "    prompt, padding=\"max_length\", max_length=tokenizer.model_max_length, truncation=True, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    text_embeddings = text_encoder(text_input.input_ids.to(torch_device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a078d6e3-5ff6-4bc7-a1c9-b162782f0a55",
   "metadata": {},
   "source": [
    "ë˜í•œ 'unconditional text embeddings'ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” íŒ¨ë”© í† í°ì— ëŒ€í•œ ì„ë² ë”©ì…ë‹ˆë‹¤. ì´ë“¤ì€ conditional text_embeddingsì™€ ê°™ì€ í˜•íƒœì˜(batch_sizeì™€ seq_length)ë¥¼ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ebd84-6748-4c35-bb78-27d2537d484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = text_input.input_ids.shape[-1]\n",
    "uncond_input = tokenizer([\"\"] * batch_size, padding=\"max_length\", max_length=max_length, return_tensors=\"pt\")\n",
    "uncond_embeddings = text_encoder(uncond_input.input_ids.to(torch_device))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ef15dc-6c10-4e8c-b377-bf629e7d6618",
   "metadata": {},
   "source": [
    "Letâ€™s concatenate the conditional and unconditional embeddings into a batch to avoid doing two forward passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ce36b-d3a5-469d-bfef-a97f0f823c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = torch.cat([uncond_embeddings, text_embeddings])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc3e4e-a7a2-42f9-bc41-1fe453cf6f0e",
   "metadata": {},
   "source": [
    "**ëœë¤ ë…¸ì´ì¦ˆ ìƒì„±**  \n",
    "ë‹¤ìŒìœ¼ë¡œ, í™•ì‚° ê³¼ì •ì˜ ì‹œì‘ì ìœ¼ë¡œ ì‚¬ìš©í•  ì´ˆê¸° ëœë¤ ë…¸ì´ì¦ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ê²ƒì€ ì´ë¯¸ì§€ì˜ ì ì¬ í‘œí˜„ì´ë©°, ì ì§„ì ìœ¼ë¡œ ë…¸ì´ì¦ˆê°€ ì œê±°ë  ê²ƒì…ë‹ˆë‹¤. ì´ ì‹œì ì—ì„œ `latent` ì´ë¯¸ì§€ëŠ” ìµœì¢… ì´ë¯¸ì§€ í¬ê¸°ë³´ë‹¤ ì‘ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ë¬¸ì œê°€ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ ëª¨ë¸ì´ ë‚˜ì¤‘ì— ì´ë¥¼ ìµœì¢…ì ì¸ 512x512 ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë³€í™˜í•  ê²ƒì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.  \n",
    "ğŸ’¡ ë†’ì´ì™€ ë„ˆë¹„ë¥¼ 8ë¡œ ë‚˜ëˆ„ëŠ” ì´ìœ ëŠ” vae ëª¨ë¸ì´ 3ê°œì˜ ë‹¤ìš´ìƒ˜í”Œë§ ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ë‹¤ìŒ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì—¬ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤: \n",
    "\n",
    "2 ** (len(vae.config.block_out_channels) - 1) == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a6b3f-6720-4f0a-a246-47f0758e83fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device=torch_device).manual_seed(123123)\n",
    "\n",
    "latents = torch.randn(\n",
    "    (batch_size, unet.config.in_channels, height // 8, width // 8),\n",
    "    generator=generator,\n",
    "    device=torch_device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac24bb5-7bae-4f87-b5d1-176195deaa70",
   "metadata": {},
   "source": [
    "**ì´ë¯¸ì§€ ë…¸ì´ì¦ˆ ì œê±°**  \n",
    "ë¨¼ì € ì´ˆê¸° ë…¸ì´ì¦ˆ ë¶„í¬ì¸ *sigma*(ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¼ ê°’)ë¡œ ì…ë ¥ì„ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤. ì´ëŠ” UniPCMultistepSchedulerì™€ ê°™ì€ ê°œì„ ëœ ìŠ¤ì¼€ì¤„ëŸ¬ì— í•„ìš”í•©ë‹ˆë‹¤:\n",
    "\n",
    "```python\n",
    "latents = latents * scheduler.init_noise_sigma\n",
    "```\n",
    "\n",
    "ë§ˆì§€ë§‰ ë‹¨ê³„ëŠ” ìˆœìˆ˜í•œ ë…¸ì´ì¦ˆì¸ latentsë¥¼ í”„ë¡¬í”„íŠ¸ì— ì„¤ëª…ëœ ì´ë¯¸ì§€ë¡œ ì ì§„ì ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë””ë…¸ì´ì§• ë£¨í”„ë¥¼ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. ë””ë…¸ì´ì§• ë£¨í”„ëŠ” ë‹¤ìŒ ì„¸ ê°€ì§€ ì‘ì—…ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. ë””ë…¸ì´ì§• ì¤‘ ì‚¬ìš©í•  ìŠ¤ì¼€ì¤„ëŸ¬ì˜ timestepsë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "2. timestepsë¥¼ ë°˜ë³µí•©ë‹ˆë‹¤.\n",
    "3. ê° timestepì—ì„œ UNet ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ ë…¸ì´ì¦ˆ ì”ì°¨ë¥¼ ì˜ˆì¸¡í•˜ê³ , ì´ë¥¼ ìŠ¤ì¼€ì¤„ëŸ¬ì— ì „ë‹¬í•˜ì—¬ ì´ì „ì˜ ë…¸ì´ì¦ˆê°€ ìˆëŠ” ìƒ˜í”Œì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ê³¼ì •ì„ í†µí•´ ì ì§„ì ìœ¼ë¡œ ë…¸ì´ì¦ˆê°€ ì œê±°ë˜ê³  ì›í•˜ëŠ” ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3782cc5-78d4-4f5c-8d55-fe32d2743ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "scheduler.set_timesteps(num_inference_steps)\n",
    "\n",
    "for t in tqdm(scheduler.timesteps):\n",
    "    # expand the latents if we are doing classifier-free guidance to avoid doing two forward passes.\n",
    "    latent_model_input = torch.cat([latents] * 2)\n",
    "\n",
    "    latent_model_input = scheduler.scale_model_input(latent_model_input, timestep=t)\n",
    "\n",
    "    # predict the noise residual\n",
    "    with torch.no_grad():\n",
    "        noise_pred = unet(latent_model_input, t, encoder_hidden_states=text_embeddings).sample\n",
    "\n",
    "    # perform guidance\n",
    "    noise_pred_uncond, noise_pred_text = noise_pred.chunk(2)\n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
    "\n",
    "    # compute the previous noisy sample x_t -> x_t-1\n",
    "    latents = scheduler.step(noise_pred, t, latents).prev_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5d519-cb5e-4a7c-b4df-7bd8ded39c2a",
   "metadata": {},
   "source": [
    "**Decode the image**\n",
    "\n",
    "The final step is to use the vae to decode the latent representation into an image and get the decoded output with sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04097f-2f16-490f-b224-d68d84b5f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale and decode the image latents with vae\n",
    "latents = 1 / 0.18215 * latents\n",
    "with torch.no_grad():\n",
    "    _image = vae.decode(latents).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72fa3cb-29ab-4f57-93f8-dbb2a94bd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image =(_image-_image.min()) / (_image.max() - _image.min())\n",
    "image = (image.permute(2,3,1,0) * 255).to(torch.uint8).cpu().numpy()\n",
    "image = image[:,:,:,0]\n",
    "image = Image.fromarray(image)\n",
    "image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
